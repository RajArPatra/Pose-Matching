{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2Eof Sonal_pose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV2zaHjYygT5"
      },
      "source": [
        "# UPLOAD ONLY THE  VIDEO WHICH NEEDS TO BE TESTED BELOW\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rusEUzJv9Ny",
        "outputId": "edb2a684-cf45-44dc-db3b-2149c04752f0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "vid_pth, _ = list(uploaded.items())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85dfda5c-566e-4463-99df-f5efd0ae99e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85dfda5c-566e-4463-99df-f5efd0ae99e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving VID-20201018-WA0019.mp4 to VID-20201018-WA0019.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM207bAhLO7b"
      },
      "source": [
        "# UPLOAD THE 2ND VIDEO TO COMPARE FROM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2vT0728LMua",
        "outputId": "edb2a684-cf45-44dc-db3b-2149c04752f0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "vid_pth2, _ = list(uploaded.items())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85dfda5c-566e-4463-99df-f5efd0ae99e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85dfda5c-566e-4463-99df-f5efd0ae99e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving VID-20201018-WA0019.mp4 to VID-20201018-WA0019.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5y7pTMxLhKj"
      },
      "source": [
        "# ONLY IF TESTING FROM CHECKPOINTS UPLOAD THE BELOW FILES."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s9dtZYzyroj"
      },
      "source": [
        "# UPLOAD ONLY THE REFRENCE FILE OF SOLO BELOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MUigUvHx6Vl",
        "outputId": "ae72dfff-b3c2-4b09-83cf-44dd0f3d5621",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded = files.upload()\n",
        "solo_pth, _ = list(uploaded.items())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5e8ba86-1110-481b-8ecb-fd8ef00fd4ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5e8ba86-1110-481b-8ecb-fd8ef00fd4ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving soloG_pose.pkl to soloG_pose.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d50GxFv-y6Sp"
      },
      "source": [
        "# UPLOAD ONLY THE REFRENCE FILE OF DUO BELOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIKVBjtJyD1E",
        "outputId": "984c8b80-ec10-40cf-89ef-483b72038fcf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded = files.upload()\n",
        "duo_pth, _ = list(uploaded.items())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cb00af4-4b98-4cec-a21b-1d9254eeb81a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2cb00af4-4b98-4cec-a21b-1d9254eeb81a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving duo_pose.pkl to duo_pose.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJG-t5xfzBMs"
      },
      "source": [
        "# UPLOAD ONLY THE REFRENCE FILE OF GROUP BELOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty0PrFf2yL0E",
        "outputId": "b13fc460-ad40-4e0c-a0b8-0303d6424c58",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded = files.upload()\n",
        "grp_pth, _ = list(uploaded.items())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d13cd324-b549-487c-8171-4670622ff89f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d13cd324-b549-487c-8171-4670622ff89f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving grp_pose.pkl to grp_pose.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiubD16FLUXT"
      },
      "source": [
        "\n",
        "\n",
        "# Mobile Net\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAR0NmaITcWS",
        "outputId": "127f3bb4-63f9-4283-876c-70c3240757dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!gdown --id 17e98AeE1fKUi9_-dwbIxqD3ODTEySP6X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17e98AeE1fKUi9_-dwbIxqD3ODTEySP6X\n",
            "To: /content/checkpoint_iter_370000.pth\n",
            "88.0MB [00:00, 242MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSqWXl4Maqe"
      },
      "source": [
        "## Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn_IpZSaLuSG"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size=3, padding=1, bn=True, dilation=1, stride=1, relu=True, bias=True):\n",
        "    modules = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)]\n",
        "    if bn:\n",
        "        modules.append(nn.BatchNorm2d(out_channels))\n",
        "    if relu:\n",
        "        modules.append(nn.ReLU(inplace=True))\n",
        "    return nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "def conv_dw(in_channels, out_channels, kernel_size=3, padding=1, stride=1, dilation=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation=dilation, groups=in_channels, bias=False),\n",
        "        nn.BatchNorm2d(in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_dw_no_bn(in_channels, out_channels, kernel_size=3, padding=1, stride=1, dilation=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation=dilation, groups=in_channels, bias=False),\n",
        "        nn.ELU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
        "        nn.ELU(inplace=True),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSkuG10cMk3z"
      },
      "source": [
        "## With Mobile Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iTeG6Z-MoBi"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        " \n",
        " \n",
        "class Cpm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.align = conv(in_channels, out_channels, kernel_size=1, padding=0, bn=False)\n",
        "        self.trunk = nn.Sequential(\n",
        "            conv_dw_no_bn(out_channels, out_channels),\n",
        "            conv_dw_no_bn(out_channels, out_channels),\n",
        "            conv_dw_no_bn(out_channels, out_channels)\n",
        "        )\n",
        "        self.conv = conv(out_channels, out_channels, bn=False)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.align(x)\n",
        "        x = self.conv(x + self.trunk(x))\n",
        "        return x\n",
        " \n",
        " \n",
        "class InitialStage(nn.Module):\n",
        "    def __init__(self, num_channels, num_heatmaps, num_pafs):\n",
        "        super().__init__()\n",
        "        self.trunk = nn.Sequential(\n",
        "            conv(num_channels, num_channels, bn=False),\n",
        "            conv(num_channels, num_channels, bn=False),\n",
        "            conv(num_channels, num_channels, bn=False)\n",
        "        )\n",
        "        self.heatmaps = nn.Sequential(\n",
        "            conv(num_channels, 512, kernel_size=1, padding=0, bn=False),\n",
        "            conv(512, num_heatmaps, kernel_size=1, padding=0, bn=False, relu=False)\n",
        "        )\n",
        "        self.pafs = nn.Sequential(\n",
        "            conv(num_channels, 512, kernel_size=1, padding=0, bn=False),\n",
        "            conv(512, num_pafs, kernel_size=1, padding=0, bn=False, relu=False)\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        trunk_features = self.trunk(x)\n",
        "        heatmaps = self.heatmaps(trunk_features)\n",
        "        pafs = self.pafs(trunk_features)\n",
        "        return [heatmaps, pafs]\n",
        " \n",
        " \n",
        "class RefinementStageBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.initial = conv(in_channels, out_channels, kernel_size=1, padding=0, bn=False)\n",
        "        self.trunk = nn.Sequential(\n",
        "            conv(out_channels, out_channels),\n",
        "            conv(out_channels, out_channels, dilation=2, padding=2)\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        initial_features = self.initial(x)\n",
        "        trunk_features = self.trunk(initial_features)\n",
        "        return initial_features + trunk_features\n",
        " \n",
        " \n",
        "class RefinementStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_heatmaps, num_pafs):\n",
        "        super().__init__()\n",
        "        self.trunk = nn.Sequential(\n",
        "            RefinementStageBlock(in_channels, out_channels),\n",
        "            RefinementStageBlock(out_channels, out_channels),\n",
        "            RefinementStageBlock(out_channels, out_channels),\n",
        "            RefinementStageBlock(out_channels, out_channels),\n",
        "            RefinementStageBlock(out_channels, out_channels)\n",
        "        )\n",
        "        self.heatmaps = nn.Sequential(\n",
        "            conv(out_channels, out_channels, kernel_size=1, padding=0, bn=False),\n",
        "            conv(out_channels, num_heatmaps, kernel_size=1, padding=0, bn=False, relu=False)\n",
        "        )\n",
        "        self.pafs = nn.Sequential(\n",
        "            conv(out_channels, out_channels, kernel_size=1, padding=0, bn=False),\n",
        "            conv(out_channels, num_pafs, kernel_size=1, padding=0, bn=False, relu=False)\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        trunk_features = self.trunk(x)\n",
        "        heatmaps = self.heatmaps(trunk_features)\n",
        "        pafs = self.pafs(trunk_features)\n",
        "        return [heatmaps, pafs]\n",
        " \n",
        " \n",
        "class PoseEstimationWithMobileNet(nn.Module):\n",
        "    def __init__(self, num_refinement_stages=1, num_channels=128, num_heatmaps=19, num_pafs=38):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv(     3,  32, stride=2, bias=False),\n",
        "            conv_dw( 32,  64),\n",
        "            conv_dw( 64, 128, stride=2),\n",
        "            conv_dw(128, 128),\n",
        "            conv_dw(128, 256, stride=2),\n",
        "            conv_dw(256, 256),\n",
        "            conv_dw(256, 512),  # conv4_2\n",
        "            conv_dw(512, 512, dilation=2, padding=2),\n",
        "            conv_dw(512, 512),\n",
        "            conv_dw(512, 512),\n",
        "            conv_dw(512, 512),\n",
        "            conv_dw(512, 512)   # conv5_5\n",
        "        )\n",
        "        self.cpm = Cpm(512, num_channels)\n",
        " \n",
        "        self.initial_stage = InitialStage(num_channels, num_heatmaps, num_pafs)\n",
        "        self.refinement_stages = nn.ModuleList()\n",
        "        for idx in range(num_refinement_stages):\n",
        "            self.refinement_stages.append(RefinementStage(num_channels + num_heatmaps + num_pafs, num_channels,\n",
        "                                                          num_heatmaps, num_pafs))\n",
        " \n",
        "    def forward(self, x):\n",
        "        backbone_features = self.model(x)\n",
        "        backbone_features = self.cpm(backbone_features)\n",
        " \n",
        "        stages_output = self.initial_stage(backbone_features)\n",
        "        for refinement_stage in self.refinement_stages:\n",
        "            stages_output.extend(\n",
        "                refinement_stage(torch.cat([backbone_features, stages_output[-2], stages_output[-1]], dim=1)))\n",
        " \n",
        "        return stages_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPacTBzNigk"
      },
      "source": [
        "## Key Point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn3DvDMpNkTA"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "\n",
        "BODY_PARTS_KPT_IDS = [[1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [1, 8], [8, 9], [9, 10], [1, 11],\n",
        "                      [11, 12], [12, 13], [1, 0], [0, 14], [14, 16], [0, 15], [15, 17], [2, 16], [5, 17]]\n",
        "BODY_PARTS_PAF_IDS = ([12, 13], [20, 21], [14, 15], [16, 17], [22, 23], [24, 25], [0, 1], [2, 3], [4, 5],\n",
        "                      [6, 7], [8, 9], [10, 11], [28, 29], [30, 31], [34, 35], [32, 33], [36, 37], [18, 19], [26, 27])\n",
        "\n",
        "\n",
        "def linspace2d(start, stop, n=10):\n",
        "    points = 1 / (n - 1) * (stop - start)\n",
        "    return points[:, None] * np.arange(n) + start[:, None]\n",
        "\n",
        "\n",
        "def extract_keypoints(heatmap, all_keypoints, total_keypoint_num):\n",
        "    heatmap[heatmap < 0.1] = 0\n",
        "    heatmap_with_borders = np.pad(heatmap, [(2, 2), (2, 2)], mode='constant')\n",
        "    heatmap_center = heatmap_with_borders[1:heatmap_with_borders.shape[0]-1, 1:heatmap_with_borders.shape[1]-1]\n",
        "    heatmap_left = heatmap_with_borders[1:heatmap_with_borders.shape[0]-1, 2:heatmap_with_borders.shape[1]]\n",
        "    heatmap_right = heatmap_with_borders[1:heatmap_with_borders.shape[0]-1, 0:heatmap_with_borders.shape[1]-2]\n",
        "    heatmap_up = heatmap_with_borders[2:heatmap_with_borders.shape[0], 1:heatmap_with_borders.shape[1]-1]\n",
        "    heatmap_down = heatmap_with_borders[0:heatmap_with_borders.shape[0]-2, 1:heatmap_with_borders.shape[1]-1]\n",
        "\n",
        "    heatmap_peaks = (heatmap_center > heatmap_left) &\\\n",
        "                    (heatmap_center > heatmap_right) &\\\n",
        "                    (heatmap_center > heatmap_up) &\\\n",
        "                    (heatmap_center > heatmap_down)\n",
        "    heatmap_peaks = heatmap_peaks[1:heatmap_center.shape[0]-1, 1:heatmap_center.shape[1]-1]\n",
        "    keypoints = list(zip(np.nonzero(heatmap_peaks)[1], np.nonzero(heatmap_peaks)[0]))  # (w, h)\n",
        "    keypoints = sorted(keypoints, key=itemgetter(0))\n",
        "\n",
        "    suppressed = np.zeros(len(keypoints), np.uint8)\n",
        "    keypoints_with_score_and_id = []\n",
        "    keypoint_num = 0\n",
        "    for i in range(len(keypoints)):\n",
        "        if suppressed[i]:\n",
        "            continue\n",
        "        for j in range(i+1, len(keypoints)):\n",
        "            if math.sqrt((keypoints[i][0] - keypoints[j][0]) ** 2 +\n",
        "                         (keypoints[i][1] - keypoints[j][1]) ** 2) < 6:\n",
        "                suppressed[j] = 1\n",
        "        keypoint_with_score_and_id = (keypoints[i][0], keypoints[i][1], heatmap[keypoints[i][1], keypoints[i][0]],\n",
        "                                      total_keypoint_num + keypoint_num)\n",
        "        keypoints_with_score_and_id.append(keypoint_with_score_and_id)\n",
        "        keypoint_num += 1\n",
        "    all_keypoints.append(keypoints_with_score_and_id)\n",
        "    return keypoint_num\n",
        "\n",
        "\n",
        "def group_keypoints(all_keypoints_by_type, pafs, pose_entry_size=20, min_paf_score=0.05, demo=False):\n",
        "    pose_entries = []\n",
        "    all_keypoints = np.array([item for sublist in all_keypoints_by_type for item in sublist])\n",
        "    for part_id in range(len(BODY_PARTS_PAF_IDS)):\n",
        "        part_pafs = pafs[:, :, BODY_PARTS_PAF_IDS[part_id]]\n",
        "        kpts_a = all_keypoints_by_type[BODY_PARTS_KPT_IDS[part_id][0]]\n",
        "        kpts_b = all_keypoints_by_type[BODY_PARTS_KPT_IDS[part_id][1]]\n",
        "        num_kpts_a = len(kpts_a)\n",
        "        num_kpts_b = len(kpts_b)\n",
        "        kpt_a_id = BODY_PARTS_KPT_IDS[part_id][0]\n",
        "        kpt_b_id = BODY_PARTS_KPT_IDS[part_id][1]\n",
        "\n",
        "        if num_kpts_a == 0 and num_kpts_b == 0:  # no keypoints for such body part\n",
        "            continue\n",
        "        elif num_kpts_a == 0:  # body part has just 'b' keypoints\n",
        "            for i in range(num_kpts_b):\n",
        "                num = 0\n",
        "                for j in range(len(pose_entries)):  # check if already in some pose, was added by another body part\n",
        "                    if pose_entries[j][kpt_b_id] == kpts_b[i][3]:\n",
        "                        num += 1\n",
        "                        continue\n",
        "                if num == 0:\n",
        "                    pose_entry = np.ones(pose_entry_size) * -1\n",
        "                    pose_entry[kpt_b_id] = kpts_b[i][3]  # keypoint idx\n",
        "                    pose_entry[-1] = 1                   # num keypoints in pose\n",
        "                    pose_entry[-2] = kpts_b[i][2]        # pose score\n",
        "                    pose_entries.append(pose_entry)\n",
        "            continue\n",
        "        elif num_kpts_b == 0:  # body part has just 'a' keypoints\n",
        "            for i in range(num_kpts_a):\n",
        "                num = 0\n",
        "                for j in range(len(pose_entries)):\n",
        "                    if pose_entries[j][kpt_a_id] == kpts_a[i][3]:\n",
        "                        num += 1\n",
        "                        continue\n",
        "                if num == 0:\n",
        "                    pose_entry = np.ones(pose_entry_size) * -1\n",
        "                    pose_entry[kpt_a_id] = kpts_a[i][3]\n",
        "                    pose_entry[-1] = 1\n",
        "                    pose_entry[-2] = kpts_a[i][2]\n",
        "                    pose_entries.append(pose_entry)\n",
        "            continue\n",
        "\n",
        "        connections = []\n",
        "        for i in range(num_kpts_a):\n",
        "            kpt_a = np.array(kpts_a[i][0:2])\n",
        "            for j in range(num_kpts_b):\n",
        "                kpt_b = np.array(kpts_b[j][0:2])\n",
        "                mid_point = [(), ()]\n",
        "                mid_point[0] = (int(round((kpt_a[0] + kpt_b[0]) * 0.5)),\n",
        "                                int(round((kpt_a[1] + kpt_b[1]) * 0.5)))\n",
        "                mid_point[1] = mid_point[0]\n",
        "\n",
        "                vec = [kpt_b[0] - kpt_a[0], kpt_b[1] - kpt_a[1]]\n",
        "                vec_norm = math.sqrt(vec[0] ** 2 + vec[1] ** 2)\n",
        "                if vec_norm == 0:\n",
        "                    continue\n",
        "                vec[0] /= vec_norm\n",
        "                vec[1] /= vec_norm\n",
        "                cur_point_score = (vec[0] * part_pafs[mid_point[0][1], mid_point[0][0], 0] +\n",
        "                                   vec[1] * part_pafs[mid_point[1][1], mid_point[1][0], 1])\n",
        "\n",
        "                height_n = pafs.shape[0] // 2\n",
        "                success_ratio = 0\n",
        "                point_num = 10  # number of points to integration over paf\n",
        "                if cur_point_score > -100:\n",
        "                    passed_point_score = 0\n",
        "                    passed_point_num = 0\n",
        "                    x, y = linspace2d(kpt_a, kpt_b)\n",
        "                    for point_idx in range(point_num):\n",
        "                        if not demo:\n",
        "                            px = int(round(x[point_idx]))\n",
        "                            py = int(round(y[point_idx]))\n",
        "                        else:\n",
        "                            px = int(x[point_idx])\n",
        "                            py = int(y[point_idx])\n",
        "                        paf = part_pafs[py, px, 0:2]\n",
        "                        cur_point_score = vec[0] * paf[0] + vec[1] * paf[1]\n",
        "                        if cur_point_score > min_paf_score:\n",
        "                            passed_point_score += cur_point_score\n",
        "                            passed_point_num += 1\n",
        "                    success_ratio = passed_point_num / point_num\n",
        "                    ratio = 0\n",
        "                    if passed_point_num > 0:\n",
        "                        ratio = passed_point_score / passed_point_num\n",
        "                    ratio += min(height_n / vec_norm - 1, 0)\n",
        "                if ratio > 0 and success_ratio > 0.8:\n",
        "                    score_all = ratio + kpts_a[i][2] + kpts_b[j][2]\n",
        "                    connections.append([i, j, ratio, score_all])\n",
        "        if len(connections) > 0:\n",
        "            connections = sorted(connections, key=itemgetter(2), reverse=True)\n",
        "\n",
        "        num_connections = min(num_kpts_a, num_kpts_b)\n",
        "        has_kpt_a = np.zeros(num_kpts_a, dtype=np.int32)\n",
        "        has_kpt_b = np.zeros(num_kpts_b, dtype=np.int32)\n",
        "        filtered_connections = []\n",
        "        for row in range(len(connections)):\n",
        "            if len(filtered_connections) == num_connections:\n",
        "                break\n",
        "            i, j, cur_point_score = connections[row][0:3]\n",
        "            if not has_kpt_a[i] and not has_kpt_b[j]:\n",
        "                filtered_connections.append([kpts_a[i][3], kpts_b[j][3], cur_point_score])\n",
        "                has_kpt_a[i] = 1\n",
        "                has_kpt_b[j] = 1\n",
        "        connections = filtered_connections\n",
        "        if len(connections) == 0:\n",
        "            continue\n",
        "\n",
        "        if part_id == 0:\n",
        "            pose_entries = [np.ones(pose_entry_size) * -1 for _ in range(len(connections))]\n",
        "            for i in range(len(connections)):\n",
        "                pose_entries[i][BODY_PARTS_KPT_IDS[0][0]] = connections[i][0]\n",
        "                pose_entries[i][BODY_PARTS_KPT_IDS[0][1]] = connections[i][1]\n",
        "                pose_entries[i][-1] = 2\n",
        "                pose_entries[i][-2] = np.sum(all_keypoints[connections[i][0:2], 2]) + connections[i][2]\n",
        "        elif part_id == 17 or part_id == 18:\n",
        "            kpt_a_id = BODY_PARTS_KPT_IDS[part_id][0]\n",
        "            kpt_b_id = BODY_PARTS_KPT_IDS[part_id][1]\n",
        "            for i in range(len(connections)):\n",
        "                for j in range(len(pose_entries)):\n",
        "                    if pose_entries[j][kpt_a_id] == connections[i][0] and pose_entries[j][kpt_b_id] == -1:\n",
        "                        pose_entries[j][kpt_b_id] = connections[i][1]\n",
        "                    elif pose_entries[j][kpt_b_id] == connections[i][1] and pose_entries[j][kpt_a_id] == -1:\n",
        "                        pose_entries[j][kpt_a_id] = connections[i][0]\n",
        "            continue\n",
        "        else:\n",
        "            kpt_a_id = BODY_PARTS_KPT_IDS[part_id][0]\n",
        "            kpt_b_id = BODY_PARTS_KPT_IDS[part_id][1]\n",
        "            for i in range(len(connections)):\n",
        "                num = 0\n",
        "                for j in range(len(pose_entries)):\n",
        "                    if pose_entries[j][kpt_a_id] == connections[i][0]:\n",
        "                        pose_entries[j][kpt_b_id] = connections[i][1]\n",
        "                        num += 1\n",
        "                        pose_entries[j][-1] += 1\n",
        "                        pose_entries[j][-2] += all_keypoints[connections[i][1], 2] + connections[i][2]\n",
        "                if num == 0:\n",
        "                    pose_entry = np.ones(pose_entry_size) * -1\n",
        "                    pose_entry[kpt_a_id] = connections[i][0]\n",
        "                    pose_entry[kpt_b_id] = connections[i][1]\n",
        "                    pose_entry[-1] = 2\n",
        "                    pose_entry[-2] = np.sum(all_keypoints[connections[i][0:2], 2]) + connections[i][2]\n",
        "                    pose_entries.append(pose_entry)\n",
        "\n",
        "    filtered_entries = []\n",
        "    for i in range(len(pose_entries)):\n",
        "        if pose_entries[i][-1] < 3 or (pose_entries[i][-2] / pose_entries[i][-1] < 0.2):\n",
        "            continue\n",
        "        filtered_entries.append(pose_entries[i])\n",
        "    pose_entries = np.asarray(filtered_entries)\n",
        "    return pose_entries, all_keypoints\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOmnD54QNmam"
      },
      "source": [
        "## Load State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDeyMTjuNyd3"
      },
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "def load_state(net, checkpoint):\n",
        "    source_state = checkpoint['state_dict']\n",
        "    target_state = net.state_dict()\n",
        "    new_target_state = collections.OrderedDict()\n",
        "    for target_key, target_value in target_state.items():\n",
        "        if target_key in source_state and source_state[target_key].size() == target_state[target_key].size():\n",
        "            new_target_state[target_key] = source_state[target_key]\n",
        "        else:\n",
        "            new_target_state[target_key] = target_state[target_key]\n",
        "            print('[WARNING] Not found pre-trained parameters for {}'.format(target_key))\n",
        "\n",
        "    net.load_state_dict(new_target_state)\n",
        "\n",
        "\n",
        "def load_from_mobilenet(net, checkpoint):\n",
        "    source_state = checkpoint['state_dict']\n",
        "    target_state = net.state_dict()\n",
        "    new_target_state = collections.OrderedDict()\n",
        "    for target_key, target_value in target_state.items():\n",
        "        k = target_key\n",
        "        if k.find('model') != -1:\n",
        "            k = k.replace('model', 'module.model')\n",
        "        if k in source_state and source_state[k].size() == target_state[target_key].size():\n",
        "            new_target_state[target_key] = source_state[k]\n",
        "        else:\n",
        "            new_target_state[target_key] = target_state[target_key]\n",
        "            print('[WARNING] Not found pre-trained parameters for {}'.format(target_key))\n",
        "\n",
        "    net.load_state_dict(new_target_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mts_JLCOGeQ"
      },
      "source": [
        "## Pose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-r3Nk46OU7_"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "def get_alpha(rate=30, cutoff=1):\n",
        "    tau = 1 / (2 * math.pi * cutoff)\n",
        "    te = 1 / rate\n",
        "    return 1 / (1 + tau / te)\n",
        "\n",
        "\n",
        "class LowPassFilter:\n",
        "    def __init__(self):\n",
        "        self.x_previous = None\n",
        "\n",
        "    def __call__(self, x, alpha=0.5):\n",
        "        if self.x_previous is None:\n",
        "            self.x_previous = x\n",
        "            return x\n",
        "        x_filtered = alpha * x + (1 - alpha) * self.x_previous\n",
        "        self.x_previous = x_filtered\n",
        "        return x_filtered\n",
        "\n",
        "\n",
        "class OneEuroFilter:\n",
        "    def __init__(self, freq=15, mincutoff=1, beta=0.05, dcutoff=1):\n",
        "        self.freq = freq\n",
        "        self.mincutoff = mincutoff\n",
        "        self.beta = beta\n",
        "        self.dcutoff = dcutoff\n",
        "        self.filter_x = LowPassFilter()\n",
        "        self.filter_dx = LowPassFilter()\n",
        "        self.x_previous = None\n",
        "        self.dx = None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.dx is None:\n",
        "            self.dx = 0\n",
        "        else:\n",
        "            self.dx = (x - self.x_previous) * self.freq\n",
        "        dx_smoothed = self.filter_dx(self.dx, get_alpha(self.freq, self.dcutoff))\n",
        "        cutoff = self.mincutoff + self.beta * abs(dx_smoothed)\n",
        "        x_filtered = self.filter_x(x, get_alpha(self.freq, cutoff))\n",
        "        self.x_previous = x\n",
        "        return x_filtered\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S8Pr9NoOdbt"
      },
      "source": [
        "class Pose:\n",
        "    num_kpts = 18\n",
        "    kpt_names = ['nose', 'neck',\n",
        "                 'r_sho', 'r_elb', 'r_wri', 'l_sho', 'l_elb', 'l_wri',\n",
        "                 'r_hip', 'r_knee', 'r_ank', 'l_hip', 'l_knee', 'l_ank',\n",
        "                 'r_eye', 'l_eye',\n",
        "                 'r_ear', 'l_ear']\n",
        "    sigmas = np.array([.26, .79, .79, .72, .62, .79, .72, .62, 1.07, .87, .89, 1.07, .87, .89, .25, .25, .35, .35],\n",
        "                      dtype=np.float32) / 10.0\n",
        "    vars = (sigmas * 2) ** 2\n",
        "    last_id = -1\n",
        "    color = [0, 224, 255]\n",
        "\n",
        "    def __init__(self, keypoints, confidence):\n",
        "        super().__init__()\n",
        "        self.keypoints = keypoints\n",
        "        self.confidence = confidence\n",
        "        self.bbox = Pose.get_bbox(self.keypoints)\n",
        "        self.id = None\n",
        "        self.filters = [[OneEuroFilter(), OneEuroFilter()] for _ in range(Pose.num_kpts)]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_bbox(keypoints):\n",
        "        found_keypoints = np.zeros((np.count_nonzero(keypoints[:, 0] != -1), 2), dtype=np.int32)\n",
        "        found_kpt_id = 0\n",
        "        for kpt_id in range(Pose.num_kpts):\n",
        "            if keypoints[kpt_id, 0] == -1:\n",
        "                continue\n",
        "            found_keypoints[found_kpt_id] = keypoints[kpt_id]\n",
        "            found_kpt_id += 1\n",
        "        bbox = cv2.boundingRect(found_keypoints)\n",
        "        return bbox\n",
        "\n",
        "    def update_id(self, id=None):\n",
        "        self.id = id\n",
        "        if self.id is None:\n",
        "            self.id = Pose.last_id + 1\n",
        "            Pose.last_id += 1\n",
        "\n",
        "    def draw(self, img):\n",
        "        assert self.keypoints.shape == (Pose.num_kpts, 2)\n",
        "\n",
        "        for part_id in range(len(BODY_PARTS_PAF_IDS) - 2):\n",
        "            kpt_a_id = BODY_PARTS_KPT_IDS[part_id][0]\n",
        "            global_kpt_a_id = self.keypoints[kpt_a_id, 0]\n",
        "            if global_kpt_a_id != -1:\n",
        "                x_a, y_a = self.keypoints[kpt_a_id]\n",
        "                cv2.circle(img, (int(x_a), int(y_a)), 3, Pose.color, -1)\n",
        "            kpt_b_id = BODY_PARTS_KPT_IDS[part_id][1]\n",
        "            global_kpt_b_id = self.keypoints[kpt_b_id, 0]\n",
        "            if global_kpt_b_id != -1:\n",
        "                x_b, y_b = self.keypoints[kpt_b_id]\n",
        "                cv2.circle(img, (int(x_b), int(y_b)), 3, Pose.color, -1)\n",
        "            if global_kpt_a_id != -1 and global_kpt_b_id != -1:\n",
        "                cv2.line(img, (int(x_a), int(y_a)), (int(x_b), int(y_b)), Pose.color, 2)\n",
        "\n",
        "\n",
        "def get_similarity(a, b, threshold=0.5):\n",
        "    num_similar_kpt = 0\n",
        "    for kpt_id in range(Pose.num_kpts):\n",
        "        if a.keypoints[kpt_id, 0] != -1 and b.keypoints[kpt_id, 0] != -1:\n",
        "            distance = np.sum((a.keypoints[kpt_id] - b.keypoints[kpt_id]) ** 2)\n",
        "            area = max(a.bbox[2] * a.bbox[3], b.bbox[2] * b.bbox[3])\n",
        "            similarity = np.exp(-distance / (2 * (area + np.spacing(1)) * Pose.vars[kpt_id]))\n",
        "            if similarity > threshold:\n",
        "                num_similar_kpt += 1\n",
        "    return num_similar_kpt\n",
        "\n",
        "\n",
        "def track_poses(previous_poses, current_poses, threshold=3, smooth=False):\n",
        "    \"\"\"Propagate poses ids from previous frame results. Id is propagated,\n",
        "    if there are at least `threshold` similar keypoints between pose from previous frame and current.\n",
        "    If correspondence between pose on previous and current frame was established, pose keypoints are smoothed.\n",
        "    :param previous_poses: poses from previous frame with ids\n",
        "    :param current_poses: poses from current frame to assign ids\n",
        "    :param threshold: minimal number of similar keypoints between poses\n",
        "    :param smooth: smooth pose keypoints between frames\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    current_poses = sorted(current_poses, key=lambda pose: pose.confidence, reverse=True)  # match confident poses first\n",
        "    mask = np.ones(len(previous_poses), dtype=np.int32)\n",
        "    for current_pose in current_poses:\n",
        "        best_matched_id = None\n",
        "        best_matched_pose_id = None\n",
        "        best_matched_iou = 0\n",
        "        for id, previous_pose in enumerate(previous_poses):\n",
        "            if not mask[id]:\n",
        "                continue\n",
        "            iou = get_similarity(current_pose, previous_pose)\n",
        "            if iou > best_matched_iou:\n",
        "                best_matched_iou = iou\n",
        "                best_matched_pose_id = previous_pose.id\n",
        "                best_matched_id = id\n",
        "        if best_matched_iou >= threshold:\n",
        "            mask[best_matched_id] = 0\n",
        "        else:  # pose not similar to any previous\n",
        "            best_matched_pose_id = None\n",
        "        current_pose.update_id(best_matched_pose_id)\n",
        "\n",
        "        if smooth:\n",
        "            for kpt_id in range(Pose.num_kpts):\n",
        "                if current_pose.keypoints[kpt_id, 0] == -1:\n",
        "                    continue\n",
        "                # reuse filter if previous pose has valid filter\n",
        "                if (best_matched_pose_id is not None\n",
        "                        and previous_poses[best_matched_id].keypoints[kpt_id, 0] != -1):\n",
        "                    current_pose.filters[kpt_id] = previous_poses[best_matched_id].filters[kpt_id]\n",
        "                current_pose.keypoints[kpt_id, 0] = current_pose.filters[kpt_id][0](current_pose.keypoints[kpt_id, 0])\n",
        "                current_pose.keypoints[kpt_id, 1] = current_pose.filters[kpt_id][1](current_pose.keypoints[kpt_id, 1])\n",
        "            current_pose.bbox = Pose.get_bbox(current_pose.keypoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wkLpSi1O0g1"
      },
      "source": [
        "## Val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfvjhYgO1vK"
      },
      "source": [
        "def normalize(img, img_mean, img_scale):\n",
        "    img = np.array(img, dtype=np.float32)\n",
        "    img = (img - img_mean) * img_scale\n",
        "    return img\n",
        "\n",
        "\n",
        "def pad_width(img, stride, pad_value, min_dims):\n",
        "    h, w, _ = img.shape\n",
        "    h = min(min_dims[0], h)\n",
        "    min_dims[0] = math.ceil(min_dims[0] / float(stride)) * stride\n",
        "    min_dims[1] = max(min_dims[1], w)\n",
        "    min_dims[1] = math.ceil(min_dims[1] / float(stride)) * stride\n",
        "    pad = []\n",
        "    pad.append(int(math.floor((min_dims[0] - h) / 2.0)))\n",
        "    pad.append(int(math.floor((min_dims[1] - w) / 2.0)))\n",
        "    pad.append(int(min_dims[0] - h - pad[0]))\n",
        "    pad.append(int(min_dims[1] - w - pad[1]))\n",
        "    padded_img = cv2.copyMakeBorder(img, pad[0], pad[2], pad[1], pad[3],\n",
        "                                    cv2.BORDER_CONSTANT, value=pad_value)\n",
        "    return padded_img, pad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51E4TqVoO-Kj"
      },
      "source": [
        "## Read Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQf4IqdvPDNw"
      },
      "source": [
        "class ImageReader(object):\n",
        "    def __init__(self, file_names):\n",
        "        self.file_names = file_names\n",
        "        self.max_idx = len(file_names)\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.idx = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.idx == self.max_idx:\n",
        "            raise StopIteration\n",
        "        img = cv2.imread(self.file_names[self.idx], cv2.IMREAD_COLOR)\n",
        "        if img.size == 0:\n",
        "            raise IOError('Image {} cannot be read'.format(self.file_names[self.idx]))\n",
        "        self.idx = self.idx + 1\n",
        "        return img\n",
        "\n",
        "\n",
        "class VideoReader(object):\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        try:  # OpenCV needs int to read from webcam\n",
        "            self.file_name = int(file_name)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.cap = cv2.VideoCapture(self.file_name)\n",
        "        if not self.cap.isOpened():\n",
        "            raise IOError('Video {} cannot be opened'.format(self.file_name))\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        was_read, img = self.cap.read()\n",
        "        if not was_read:\n",
        "            raise StopIteration\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE41MelzPgbq"
      },
      "source": [
        "## Infer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrKQPHDVfL93",
        "outputId": "1cdf49e2-dc08-43f1-9c2a-110d615a9fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device='cuda'\n",
        "else :\n",
        "   device='cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAsCyzf2Pikc"
      },
      "source": [
        "\n",
        "def infer_fast(net, img, net_input_height_size, stride, upsample_ratio, cpu,\n",
        "               pad_value=(0, 0, 0), img_mean=(128, 128, 128), img_scale=1/256):\n",
        "    height, width, _ = img.shape\n",
        "    scale = net_input_height_size / height\n",
        "\n",
        "    scaled_img = cv2.resize(img, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "    scaled_img = normalize(scaled_img, img_mean, img_scale)\n",
        "    min_dims = [net_input_height_size, max(scaled_img.shape[1], net_input_height_size)]\n",
        "    padded_img, pad = pad_width(scaled_img, stride, pad_value, min_dims)\n",
        "\n",
        "    tensor_img = torch.from_numpy(padded_img).permute(2, 0, 1).unsqueeze(0).float()\n",
        "    #if not cpu:\n",
        "        #tensor_img = tensor_img.cuda()\n",
        "    net=net.to(device)\n",
        "    tensor_img=tensor_img.to(device)\n",
        "    stages_output = net(tensor_img)\n",
        "\n",
        "    stage2_heatmaps = stages_output[-2]\n",
        "    heatmaps = np.transpose(stage2_heatmaps.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
        "    heatmaps = cv2.resize(heatmaps, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    stage2_pafs = stages_output[-1]\n",
        "    pafs = np.transpose(stage2_pafs.squeeze().cpu().data.numpy(), (1, 2, 0))\n",
        "    pafs = cv2.resize(pafs, (0, 0), fx=upsample_ratio, fy=upsample_ratio, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return heatmaps, pafs, scale, pad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nSh2rgaRsHu"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftQE_8Mb5B1E",
        "outputId": "ea69a807-e609-49f6-8c8b-6e76a0de956e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!gdown --id 17e98AeE1fKUi9_-dwbIxqD3ODTEySP6X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17e98AeE1fKUi9_-dwbIxqD3ODTEySP6X\n",
            "To: /content/checkpoint_iter_370000.pth\n",
            "88.0MB [00:00, 114MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNMT-KK_Rt5u"
      },
      "source": [
        "checkpoint_path = 'checkpoint_iter_370000.pth'\n",
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "load_state(model, checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUg7m6AOPa6_"
      },
      "source": [
        "model = model.eval()\n",
        "\n",
        "stride = 8\n",
        "upsample_ratio = 4\n",
        "num_keypoints = Pose.num_kpts\n",
        "#previous_poses = []\n",
        "delay = 33\n",
        "\n",
        "height_size = 256\n",
        "cpu = True\n",
        "track = True\n",
        "smooth = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbM_k6Y7VAi"
      },
      "source": [
        "def extract_pose(frame_provider, model, num_keypoints, height_size=256,\n",
        "                 stride=8, upsample_ratio=4, cpu=True,\n",
        "                 is_draw=False):\n",
        "    \n",
        "    all_poses = []\n",
        "    i = 0\n",
        "    for img in frame_provider:\n",
        "        print(i)\n",
        "        i += 1\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = infer_fast(model, img, height_size, stride, upsample_ratio, cpu)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "\n",
        "        for kpt_idx in range(num_keypoints):\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs, demo=True)\n",
        "\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "\n",
        "        current_poses = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "            \n",
        "            pose = Pose(pose_keypoints, pose_entries[n][18])\n",
        "            current_poses.append(pose)\n",
        "        all_poses.append(current_poses)\n",
        "        if is_draw:\n",
        "            for pose in current_poses:\n",
        "                pose.draw(img)\n",
        "\n",
        "            img = cv2.addWeighted(orig_img, 0.6, img, 0.4, 0)\n",
        "\n",
        "        return current_poses, img\n",
        "        \n",
        "    return all_poses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_ICP62rCws0"
      },
      "source": [
        "def gt_all_pose(frame_provider_cp_1):\n",
        "  all_poses = []\n",
        "  i = 0\n",
        "  for img in frame_provider_cp_1:\n",
        "      i+=1\n",
        "      if(i%60 != 0):\n",
        "          continue\n",
        "      #print(i)\n",
        "      \n",
        "      heatmaps, pafs, scale, pad = infer_fast(model, img, height_size, stride, upsample_ratio, cpu)\n",
        "\n",
        "      total_keypoints_num = 0\n",
        "      all_keypoints_by_type = []\n",
        "\n",
        "      for kpt_idx in range(num_keypoints):\n",
        "          total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "      \n",
        "      pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs, demo=True)\n",
        "\n",
        "      current_poses = []\n",
        "      for n in range(len(pose_entries)):\n",
        "          if len(pose_entries[n]) == 0:\n",
        "              continue\n",
        "          pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "          for kpt_id in range(num_keypoints):\n",
        "              if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                  pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                  pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "          pose = Pose(pose_keypoints, pose_entries[n][18])\n",
        "          current_poses.append(pose)\n",
        "      all_poses.append(current_poses)\n",
        "  return   all_poses    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7HhVNfz7xeK"
      },
      "source": [
        "def get_similarity(a, b, threshold=0.5):\n",
        "    num_similar_kpt = 0\n",
        "    sim = 0\n",
        "    for kpt_id in range(Pose.num_kpts):\n",
        "        if a.keypoints[kpt_id, 0] != -1 and b.keypoints[kpt_id, 0] != -1:\n",
        "            distance = np.sum((a.keypoints[kpt_id] - b.keypoints[kpt_id]) ** 2)\n",
        "            area = max(a.bbox[2] * a.bbox[3], b.bbox[2] * b.bbox[3])\n",
        "            similarity = np.exp(-distance / (2 * (area + np.spacing(1)) * Pose.vars[kpt_id]))\n",
        "            sim += similarity\n",
        "            if similarity > threshold:\n",
        "                num_similar_kpt += 1\n",
        "    return num_similar_kpt, sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Uf0_dvrd6Q"
      },
      "source": [
        "#from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "def similarity_check(ref_poses,poses_2):\n",
        "    cnt = 0\n",
        "    similarity_overall = 0\n",
        "    sim_p_overall = 0 \n",
        "\n",
        "    for r_p in ref_poses:\n",
        "        \n",
        "        for pp in poses_2:\n",
        "            #track_poses(r_p, pp, smooth=True)\n",
        "            if len(r_p)==len(pp):\n",
        "                for i in range(len(r_p)):\n",
        "                    sim_p, sim = get_similarity(r_p[i], pp[i])\n",
        "                    #print(sim_p, sim)\n",
        "                    similarity_overall += sim\n",
        "                    sim_p_overall += sim_p\n",
        "                    cnt += 1\n",
        "        \n",
        "    print(similarity_overall/cnt+1e-10)\n",
        "    print(sim_p_overall/cnt+1e-10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAc1JubhNe8V"
      },
      "source": [
        "# Checkpoint Generation\n",
        "Run the below on ly if you need to generate the checkpoint of the first uploaded video and store it as pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bQsM3EY1d4x"
      },
      "source": [
        "import pickle\n",
        "output_file=\"out.pkl\"\n",
        "video_file=str(vid_pth)\n",
        "with open(output_file, 'wb') as output:\n",
        "  reader=VideoReader(video_file)\n",
        "  ref=gt_all_pose(reader)\n",
        "  pickle.dump(ref, output, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3J7l9fPD_86"
      },
      "source": [
        "# E2E Pose comparasion\n",
        "Run this if you have uploaded the checkpoints files earlier, or else this would terminate with nmaee error.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PH3BwSvkMYr"
      },
      "source": [
        "import pickle\n",
        "from numpy.random import randint\n",
        "def E2E(path):\n",
        "   frame_provider1=VideoReader(path)\n",
        "   test_pose=gt_all_pose(frame_provider1)[:]\n",
        "   if len(test_pose)>10:\n",
        "    values = randint(0,len(test_pose),10)\n",
        "   else:\n",
        "     values = randint(0,len(test_pose),5)\n",
        "   vid_type=(np.array([len(test_pose[i]) for i in values]).mean())\n",
        "   \n",
        "   #vid_type=int(vid_type) if vid_type-round(vid_type)<=0 else int(vid_type)+1\n",
        "   #print(vid_type)\n",
        "   vid_type=round(vid_type)\n",
        "   if(vid_type==0):\n",
        "     print('0')\n",
        "     return\n",
        "   elif(vid_type==1):\n",
        "     with open(str(solo_pth), 'rb') as input:\n",
        "       print('Video_type: solo')\n",
        "       rf2 = pickle.load(input)\n",
        "   elif(vid_type==2):\n",
        "     with open(str(duo_pth), 'rb') as input:\n",
        "       print('Video_type: duo')\n",
        "       rf2 = pickle.load(input)\n",
        "   else:\n",
        "     with open(str(grp_pth), 'rb') as input:\n",
        "       print('Video_type: group')\n",
        "       rf2 = pickle.load(input)\n",
        "   similarity_check(rf2[:],test_pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6GKvxDpERHe"
      },
      "source": [
        "# Testing E2E\n",
        "Run the cell below to campare  the video from pre-generated checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYR42kC3eyk",
        "outputId": "cc7dcc39-6a30-4ef0-c433-12d474f2d5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "E2E(str(vid_pth))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.988551117440555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkVJxGgKBW7o"
      },
      "source": [
        "def vid_E2E(ref,test):\n",
        "   frame_provider1=VideoReader(ref)\n",
        "   ref_pose=gt_all_pose(frame_provider1)[:]\n",
        "   frame_provider2=VideoReader(test)\n",
        "   test_pose=gt_all_pose(frame_provider2)[:]\n",
        "   x=similarity_exp(ref_pose,test_pose)\n",
        "   y=similarity_exp(ref_pose,ref_pose)\n",
        "\n",
        "   #print(x)\n",
        "   #print(y)\n",
        "   print(x/(y+2e-10)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y5sYg-PKREc"
      },
      "source": [
        "# Testing vid_E2E\n",
        "Run the cell below if you are testing similarity between 2 videos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OqtIDgVODqb",
        "outputId": "1b888f03-1a52-410a-883c-c1c44c73d453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "vid_E2E(str(vid_pth),str(vid_pth2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.539550337786898\n",
            "7.374023530293396\n",
            "48.00025824639682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXocKUr570qB",
        "outputId": "e3feb781-9eb0-4402-8e18-2515c8713b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python /content/a.py -v /content/couple.mp4 -s /content/soloG_pose.pkl -d /content/duo_pose.pkl -g /content/grp_pose.pkl -w /content/checkpoint_iter_370000.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.988551117440555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghtC27oFX36r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}